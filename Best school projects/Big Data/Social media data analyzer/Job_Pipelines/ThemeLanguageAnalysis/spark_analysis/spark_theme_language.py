# -*- coding: utf-8 -*-
"""bigdata-themelangfreq

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tduoXwDEWVacYt0bk_ufuBfqm30EKfi2

# Install Necessary Packages
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import split, col, countDistinct, sum as _sum, desc, row_number

"""# Init Spark"""

# Initialize Spark
spark = SparkSession.builder.appName("Theme-Frequency-By-Language").getOrCreate()

# 1. Load and parse the data (replace with your actual file)
df = spark.read.text("s3://sg.edu.sit.inf2006.aaronlam/ThemeLanguageAnalysisFolder/mr_preprocessing/output/")

# 2. Parse into columns (Language, Theme, Count)
parsed_df = df.withColumn("temp", split(col("value"), " - ")) \
              .withColumn("language", col("temp")[0]) \
              .withColumn("theme_count", split(col("temp")[1], "\t")) \
              .withColumn("theme", col("theme_count")[0]) \
              .withColumn("count", col("theme_count")[1].cast("integer")) \
              .drop("value", "temp", "theme_count")

# Register the parsed DataFrame as a temporary view for easier querying
parsed_df.createOrReplaceTempView("theme_language_counts")

"""# Analysis

## 1a. Top 3 languages of all themes
"""

top_languages_df = spark.sql("""
    SELECT
        language,
        SUM(count) AS total_count
    FROM theme_language_counts
    GROUP BY language
    ORDER BY total_count DESC
    LIMIT 3
""")

top_languages = [row.language for row in top_languages_df.collect()]

"""
## 1b. Top 3 themes
"""

top_themes_df = spark.sql("""
    SELECT
        theme,
        SUM(count) AS total_count
    FROM theme_language_counts
    GROUP BY theme
    ORDER BY total_count DESC
    LIMIT 3
""")

top_themes = [row.theme for row in top_themes_df.collect()]

"""## 2. Themes with the largest % of the top languages

"""

theme_language_percentage_df = spark.sql("""
    WITH ThemeTotalCounts AS (
        SELECT
            theme,
            SUM(count) AS theme_total
        FROM theme_language_counts
        GROUP BY theme
    ),
    ThemeLanguageCounts AS (
        SELECT
            theme,
            language,
            SUM(count) AS language_count
        FROM theme_language_counts
        WHERE language IN ('{}', '{}', '{}') -- Insert top 3 languages
        GROUP BY theme, language
    )
    SELECT
        tlc.theme,
        tlc.language,
        tlc.language_count,
        ttc.theme_total,
        (tlc.language_count / ttc.theme_total) * 100 AS percentage
    FROM ThemeLanguageCounts tlc
    JOIN ThemeTotalCounts ttc ON tlc.theme = ttc.theme
""".format(top_languages[0], top_languages[1], top_languages[2]))

theme_top_3_percentage_df = theme_language_percentage_df.groupBy("theme") \
    .agg(_sum("percentage").alias("top_3_percentage")) \
    .orderBy(desc("top_3_percentage"))

top_3_themes_df = theme_top_3_percentage_df.limit(3)
top_3_themes = [row.theme for row in top_3_themes_df.collect()]

"""## Theme with the MOST & LEAST number of Languages"""

theme_language_count_df = parsed_df.groupBy("theme") \
    .agg(countDistinct("language").alias("num_languages"))

top_theme_df = theme_language_count_df.orderBy(desc("num_languages"))
top_theme_languages = top_theme_df.first()
max_language_count = top_theme_languages.num_languages
themes_with_max = top_theme_df.filter(col("num_languages") == max_language_count).collect()

least_theme_df = theme_language_count_df.orderBy("num_languages")
least_theme_languages = least_theme_df.first()
min_language_count = least_theme_languages.num_languages
themes_with_min = least_theme_df.filter(col("num_languages") == min_language_count).collect()

"""## Final Output Analysis"""

from pyspark.sql import Row

# Prepare the analysis output as a list of strings
output_lines = []

output_lines.append("Top 3 Languages Across All Themes:")
for lang in top_languages:
    output_lines.append(f"- {lang}")

output_lines.append("\nTop 3 Themes:")
for theme in top_themes:
    output_lines.append(f"- {theme}")

output_lines.append("\nTop 3 themes with the highest percentage of the Top 3 languages:")
for theme in top_3_themes:
    output_lines.append(f"\nTheme: {theme}")
    theme_language_percentages = theme_language_percentage_df.filter(col("theme") == theme).orderBy(desc("percentage")).collect()
    for row in theme_language_percentages:
        output_lines.append(f"  Language: {row.language}, Percentage: {row.percentage:.2f}%")

output_lines.append("\nTheme(s) with the Most Number of Languages:")
for row in themes_with_max:
    output_lines.append(f"Theme: {row.theme}, with {row.num_languages} Languages!")

output_lines.append("\nTheme(s) with the Least Number of Languages:")
for row in themes_with_min:
    output_lines.append(f"Theme: {row.theme}, with {row.num_languages} Languages.")

# Convert the list of strings to a DataFrame
text_df = spark.createDataFrame([Row(value=line) for line in output_lines])

# Define your S3 output path
s3_text_output_path = "s3://sg.edu.sit.inf2006.aaronlam/ThemeLanguageAnalysisFolder/spark_analysis/text_output/"

# Write the text lines to S3 as a single file
text_df.coalesce(1).write.mode("overwrite").text(s3_text_output_path)

print(f"Analysis results written to '{s3_text_output_path}'")


# analysis_output_file = "analysis_results.txt" ### UPDATE_FILE_PATH_HERE

# with open(analysis_output_file, "w") as f:
#     f.write("Top 3 Languages Across All Themes:\n")
#     for lang in top_languages:
#         f.write(f"- {lang}\n")

#     f.write("\nTop 3 Themes:\n")
#     for theme in top_themes:
#         f.write(f"- {theme}\n")

#     f.write("\nTop 3 themes with the highest percentage of the Top 3 languages:\n")
#     for theme in top_3_themes:
#         f.write(f"\nTheme: {theme}\n")
#         theme_language_percentages = theme_language_percentage_df.filter(col("theme") == theme).orderBy(desc("percentage")).collect()
#         for row in theme_language_percentages:
#             f.write(f"  Language: {row.language}, Percentage: {row.percentage:.2f}%\n")

#     f.write("\nTheme(s) with the Most Number of Languages:\n")
#     for row in themes_with_max:
#         f.write(f"Theme: {row.theme}, with {row.num_languages} Languages!\n")

#     f.write("\nTheme(s) with the Least Number of Languages:\n")
#     for row in themes_with_min:
#         f.write(f"Theme: {row.theme}, with {row.num_languages} Languages.\n")

# print(f"Analysis results have been printed to '{analysis_output_file}'")

# # Output path in S3
output_path = "s3://sg.edu.sit.inf2006.aaronlam/ThemeLanguageAnalysisFolder/spark_analysis/csv_output/"

# Save DataFrame as CSV
# Write DataFrames into separate subdirectories
parsed_df.coalesce(1).write.mode("overwrite").option("header", "true").csv(output_path)

# Stop Spark
spark.stop()

